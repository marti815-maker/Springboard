{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,balanced_accuracy_score,confusion_matrix\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_to_predict='oil'\n",
    "df=pd.read_csv('../raw data/common purchases.csv',index_col='Member_number')\n",
    "\n",
    "y=df[product_to_predict]\n",
    "df.drop(columns=[product_to_predict],inplace=True)\n",
    "X=df\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an unbalanced dataset.  Here we join the training data, upsample the minority case, and then un-join.\n",
    "This will prevent the algorithms from fixating on one case during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=X_train.join(y_train,on='Member_number',how='outer')\n",
    "minority_df=train_df[train_df[product_to_predict]==1]\n",
    "majority_df=train_df[train_df[product_to_predict]==0]\n",
    "minority_df=resample(minority_df,replace=True,n_samples=len(majority_df))\n",
    "upsampled_df=pd.concat([majority_df,minority_df])\n",
    "y_train=upsampled_df[product_to_predict]\n",
    "X_train=upsampled_df.drop(columns=[product_to_predict])\n",
    "\n",
    "X_train=X_train.reset_index(drop=True).to_numpy()\n",
    "X_test=X_test.reset_index(drop=True).to_numpy()\n",
    "y_train=y_train.reset_index(drop=True).to_numpy()\n",
    "y_test=y_test.reset_index(drop=True).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'criterion': 'entropy', 'n_estimators': 1000} \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       743\n",
      "         1.0       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.95       780\n",
      "   macro avg       0.48      0.50      0.49       780\n",
      "weighted avg       0.91      0.95      0.93       780\n",
      "\n",
      "[[738   5]\n",
      " [ 37   0]]\n"
     ]
    }
   ],
   "source": [
    "rf_params={'criterion':['gini','entropy'],\n",
    "          'n_estimators':[10,100,1000]}\n",
    "rf_model=GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "                      param_grid=rf_params,\n",
    "                      scoring='balanced_accuracy', \n",
    "                      cv=5)\n",
    "rf_model.fit(X_train,y_train)\n",
    "rf_pred=rf_model.predict(X_test)\n",
    "print('Best Parameters: ',rf_model.best_params_,'\\n')\n",
    "print(classification_report(y_test,rf_pred))\n",
    "print(confusion_matrix(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest fixated on only one class and seems to be worthless.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_neighbors': 2, 'p': 1, 'weights': 'uniform'} \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       743\n",
      "         1.0       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.94       780\n",
      "   macro avg       0.48      0.50      0.49       780\n",
      "weighted avg       0.91      0.94      0.92       780\n",
      "\n",
      "[[736   7]\n",
      " [ 37   0]]\n"
     ]
    }
   ],
   "source": [
    "knn_params={'n_neighbors':range(1,10),\n",
    "           'weights':['uniform', 'distance'],\n",
    "           'p':[1,2]}\n",
    "knn_model=GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                      param_grid=knn_params,\n",
    "                      scoring='balanced_accuracy', \n",
    "                      cv=5)\n",
    "knn_model.fit(X_train,y_train)\n",
    "knn_pred=knn_model.predict(X_test)\n",
    "print('Best Parameters: ',knn_model.best_params_,'\\n')\n",
    "print(classification_report(y_test,knn_pred))\n",
    "print(confusion_matrix(y_test,knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "K-Nearest Neighbors also fixated on one class, only doing narrowly better at recall on the product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'l1_ratio': 1, 'penalty': 'l1', 'solver': 'saga'} \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.65      0.77       743\n",
      "         1.0       0.04      0.32      0.08        37\n",
      "\n",
      "    accuracy                           0.64       780\n",
      "   macro avg       0.50      0.49      0.43       780\n",
      "weighted avg       0.91      0.64      0.74       780\n",
      "\n",
      "[[485 258]\n",
      " [ 25  12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15178\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n"
     ]
    }
   ],
   "source": [
    "logres_params={'penalty':['l1', 'l2', 'elasticnet'],\n",
    "              'solver':['saga'],\n",
    "              'l1_ratio':[1]}\n",
    "logres_model=GridSearchCV(estimator=LogisticRegression(class_weight='balanced'),\n",
    "                        param_grid=logres_params,\n",
    "                        scoring='roc_auc', \n",
    "                        cv=5)\n",
    "logres_model.fit(X_train,y_train)\n",
    "logres_pred=logres_model.predict(X_test)\n",
    "print('Best Parameters: ',logres_model.best_params_,'\\n')\n",
    "print(classification_report(y_test,logres_pred))\n",
    "print(confusion_matrix(y_test,logres_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LogRes has something we can work with, but its recall is a bit low.  We don't care much about false positives in\n",
    "this business decision, so let's drop the cut-off value a bit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.48      0.64       743\n",
      "         1.0       0.05      0.51      0.09        37\n",
      "\n",
      "    accuracy                           0.48       780\n",
      "   macro avg       0.50      0.50      0.36       780\n",
      "weighted avg       0.91      0.48      0.61       780\n",
      "\n",
      "[[356 387]\n",
      " [ 18  19]]\n"
     ]
    }
   ],
   "source": [
    "logres_probs=logres_model.predict_proba(X_test)\n",
    "new_pred=[1.0 if prob>.40 else 0.0 for prob in logres_probs[:,1]]\n",
    "print(classification_report(y_test,new_pred))\n",
    "print(confusion_matrix(y_test,new_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new cutt-off we can accurately flag 51% of would-be purchasers, while still correctly identifying\n",
    "356 people who likely wouldn't have bought the product anyway.  This is actionable.\n",
    "\n",
    "Final model: LogRes with 'l1_ratio': 1, 'penalty': 'l1', 'solver': 'saga' and cutt-off probability of 40%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
